v1: 针对域名扫描,没有针对ip. ip相同的域名会造成重复

v1.1: 先获取ip列表， 以{ip：[domain]}形式存储为字典，并生成ip列表文件用于split和扫描。解决重复扫描问题
    顺序查询域名ip, 速度相当慢,未等待运行结束!

-----------------------------------------------------------------------------------------------------------------------
v1.2: 改为多线程获取域名ip,并按ip为键值,进行存储. (测试1万个域名， dns请求过程中会卡住. q.task_done()遗漏导致~~~)
v1.3: v1.3 输入为ip列表文件, 输入名为：file_IPs中的file。已经有了_IPs和_IP2Domain文件，仅重新扫描IP 

-----------------------------------------------------------------------------------------------------------------------
v2: a.将原始文件切分为sub_num个子文件，以此为单位，进行批量域名请求，并对其中的ip进行扫描；
    b.依次处理每个子文件， 但需要注意的是，只有list2 不用考虑之间可能存在重复。
      ip-domain dic：映射关系，去重插入，维持一份！
      list1：IP列表，需要去重插入，只把新增作为list3,存文件，作为第n批扫描ip列表。

注: v1.2 所有列表，一次性请求域名的IP。  建议当域名总数不多时，使用。 
    v1.3 当输入为ip列表时, 建议使用   
    v2.0 列表分为sub_num次，分别请求，请求一次扫描一次。当域名数较多时，建议使用！
    分批查询域名，返回无法解析的域名数也明显减少！


--------------------------------------------------------------------------------------
extract.py : 按照[]长度, 端口数或对应域名数, 筛选异常IP.
extract-loc.py : 同上，同时加上对IP的定位信息，并保存
extract-addomain.py: 对extract的open文件，即端口数过多的， 查找IP对应的域名，并插入保存。